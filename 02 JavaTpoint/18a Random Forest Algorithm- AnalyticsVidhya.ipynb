{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It builds decision trees on different samples and takes their majority vote for classification and average in case of regression."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "random forest is a bagging techniques, because model are built in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning/Techniques"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ensemble simply means combining multiple models.\n",
    "Thus a collection of models is used to make predictions rather than an individual model.\n",
    "\n",
    "Ensemble uses two types of methods:\n",
    "    1.Bagging\n",
    "    2.Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-also known as Bootstrap Aggregation\n",
    "-it chooses a random sample, each model is generated from this samples (Bootstrap Samples) provided by the Original Data with replacement known as row sampling. \n",
    "\n",
    "This step of row sampling with replacement is called bootstrap. \n",
    "\n",
    "Now each model is trained independently which generates results. \n",
    "\n",
    "The final output is based on majority voting after combining(Aggregation) the results of all models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps involved in random forest algorithm:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Step 1: 'n' number of random samples are taken from the data set having 'k' number of records.\n",
    "\n",
    "Step 2: Individual decision trees are constructed for each sample.\n",
    "\n",
    "Step 3: Each decision tree will generate an output.\n",
    "\n",
    "Step 4: Final output is considered based on Majority Voting or Averaging for Classification and regression respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Features of Random Forest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Diversity:\n",
    "Not all attributes/variables/features are considered while making an individual tree, each tree is different.\n",
    "\n",
    "2.Immune to the curse of dimensionality- Since each tree does not consider all the features, the feature space is reduced.\n",
    "3. Parallelization:\n",
    "Each tree is created independently out of different data and attributes. This means that we can make full use of the CPU to build random forests.\n",
    "\n",
    "4.  Train-Test split:In a random forest we don’t have to segregate the data for train and test as there will always be 30% of the data which is not seen by the decision tree.\n",
    "\n",
    "5.  Stability- Stability arises because the result is based on majority voting/ averaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference Between Decision Tree & Random Forest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Decision trees normally suffer from the problem of overfitting if it’s allowed to grow without any control.\n",
    "While in RandomForest, final output is based on average or majority ranking and hence the problem of overfitting is taken care\n",
    "of..\n",
    " \n",
    "A single decision tree is faster in computation.\n",
    "Random Forest is comparatively slower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Hyperparameters Of Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following hyperparameters increases the predictive power:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. n_estimators: number of trees the algorithm builds before averaging the predictions.\n",
    "2. max_features: maximum number of features random forest considers while splitting a node.\n",
    "3. mini_sample_leaf: determines the minimum number of leaves required to split an internal node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following hyperparameters increases the speed:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. n_jobs– it tells the engine how many processors it is allowed to use. If the value is 1, it can use only one processor but if the value is -1 there is no limit.\n",
    "\n",
    "2. random_state– controls randomness of the sample. The model will always produce the same results if it has a definite value of random state and if it has been given the same hyperparameters and the same training data.\n",
    "\n",
    "3. oob_score – OOB means out of the bag. It is a random forest cross-validation method. In this one-third of the sample is not used to train the data instead used to evaluate its performance. These samples are called out of bag samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Implementaiton of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>cholestrol</th>\n",
       "      <th>heart disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex   BP  cholestrol  heart disease\n",
       "0   70    1  130         322              1\n",
       "1   67    0  115         564              0\n",
       "2   57    1  124         261              1\n",
       "3   64    1  128         263              0\n",
       "4   74    0  120         269              0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('heart_v2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('heart disease',axis=1)\n",
    "# Putting response variable to y\n",
    "y = df['heart disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((189, 4), (81, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc=RandomForestClassifier(n_estimators=100,n_jobs=-1,max_depth=5,random_state=42,oob_score=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "max_depth : int, default=None\n",
    "    The maximum depth of the tree. If None, then nodes are expanded until\n",
    "    all leaves are pure or until all leaves contain less than\n",
    "    min_samples_split samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 208 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_jobs=-1, oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.656084656084656"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rfc.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s do hyperparameter tuning for Random Forest using GridSearchCV and fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make another instance of the classifier\n",
    "rfc = RandomForestClassifier(random_state=42,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a variable to store parameters listings\n",
    "params={\n",
    "    'max_depth':[2,3,5,10,20],\n",
    "    'min_samples_leaf':[5,10,20,50,100,200],\n",
    "    'n_estimators':[10,25,30,50,100,200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import GridsearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an instance of GridsearchCV\n",
    "grid_search=GridSearchCV(estimator=rfc,param_grid=params,cv=4,n_jobs=-1,verbose=1,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:   24.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 5, 10, 20],\n",
       "                         'min_samples_leaf': [5, 10, 20, 50, 100, 200],\n",
       "                         'n_estimators': [10, 25, 30, 50, 100, 200]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the data on GridsearchCV\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6985815602836879"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, min_samples_leaf=10, n_estimators=10,\n",
       "                       n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best = grid_search.best_estimator_\n",
    "rf_best"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The above output gives the best parameters values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
