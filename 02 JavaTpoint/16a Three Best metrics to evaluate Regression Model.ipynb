{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7319864",
   "metadata": {},
   "source": [
    "### 3 Best metrics to evaluate Regression Model?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb231ee2",
   "metadata": {},
   "source": [
    "There are 3 main metrics for model evaluation in regression:\n",
    "\n",
    "1. R Square/Adjusted R Square\n",
    "2. Mean Square Error(MSE)/Root Mean Square Error(RMSE)\n",
    "3. Mean Absolute Error(MAE)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "274b12d4",
   "metadata": {},
   "source": [
    "R Square measures how much variability in output can be explained by the model. It is the square of the Correlation Coefficient(R) and that is why it is called R Square."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e57b9d7",
   "metadata": {},
   "source": [
    "<img src='r2.jpg' width=300 height=50>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd0ba644",
   "metadata": {},
   "source": [
    "- R Square value is between 0 to 1 \n",
    "- a bigger value indicates a better fit between prediction and actual value.\n",
    "- However, it does not take into consideration of overfitting problem, because it fails to generalize with so many independent variables\n",
    "- thats why we need adjusted R-sqaure in that case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb1a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted R Sqaure\n",
    "\n",
    "from sklearn.metrics import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59d2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Square Error(MSE)/Root Mean Square Error(RMSE)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c6ae8ea",
   "metadata": {},
   "source": [
    "MSE is an absolute measure of the goodness for the fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c3a5d9",
   "metadata": {},
   "source": [
    "<img src='mse.jpg'>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c5e2591",
   "metadata": {},
   "source": [
    "Root Mean Square Error(RMSE) is the square root of MSE. It is used more commonly than MSE because firstly sometimes MSE value can be too big to compare easily. Secondly, MSE is calculated by the square of error, and thus square root brings it back to the same level of prediction error and makes it easier for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be93320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "# print(mean_squared_error(y_test, y_pred))\n",
    "# print(math.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "# MSE: 2017904593.23\n",
    "# RMSE: 44921.092965684235"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37baf18",
   "metadata": {},
   "source": [
    "### Mean Absolute Error(MAE)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "072cf346",
   "metadata": {},
   "source": [
    "Mean Absolute Error(MAE) is similar to Mean Square Error(MSE). However, instead of the sum of square of error in MSE, MAE is taking the sum of the absolute value of error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf3d24a",
   "metadata": {},
   "source": [
    "<img src='mae.jpg'>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58389e81",
   "metadata": {},
   "source": [
    "Compare to MSE or RMSE, MAE is a more direct representation of sum of error terms. MSE gives larger penalization to big prediction error by square it while MAE treats all errors the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5f1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "# print(mean_absolute_error(y_test, y_pred))\n",
    "#MAE: 26745.1109986"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe9e3bd1",
   "metadata": {},
   "source": [
    "Overall Recommendation/Conclusion\n",
    "\n",
    "R Square/Adjusted R Square is better used to explain the model to other people because you can explain the number as a percentage of the output variability. MSE, RMSE, or MAE are better be used to compare performance between different regression models. Personally, I would prefer using RMSE and I think Kaggle also uses it to assess the submission. However, it makes total sense to use MSE if the value is not too big and MAE if you do not want to penalize large prediction errors.\n",
    "\n",
    "Adjusted R square is the only metric here that considers the overfitting problem. R Square has a direct library in Python to calculate but I did not find a direct library to calculate Adjusted R square except using the statsmodel results. If you really want to calculate Adjusted R Square, you can use statsmodel or use its mathematic formula directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece312e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to calculate r2 and adjusted r2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
