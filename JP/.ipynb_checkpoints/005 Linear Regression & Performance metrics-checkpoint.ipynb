{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A Supervised ml algortim\n",
    "- Models a linear relationship between a dependent (y) and one or more independent (y) variables,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='lr.jpg' width=250, hight=250>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                    img source: Javatpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically\n",
    "\n",
    "   y= mX+ b + ε\n",
    "   \n",
    "   c= intercept of the line \n",
    "   \n",
    "   m = regression coefficient/ slope\n",
    "   \n",
    "   ε = random error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Types of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Linear Regression: \n",
    "* it has only one input variable for prediction\n",
    "\n",
    "Multiple Linear regression: \n",
    "* more than one input variable used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Regression line??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It best fit line line showing the relationship between the input and output variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A regression line can show two types of relationship:\n",
    "\n",
    "1.Positive Linear Relationship: output increase with input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='lr1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Negative Linear Relationship: output decreases with increasing input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='lr3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best fit line:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Regression always try to find the best fit line that means the error between predicted values and actual values should be minimized.\n",
    "* The best fit line will have the least error.\n",
    "* The different values for weights or coefficient of lines (a0, a1) gives a different line of regression, so we need to calculate the best values for a0 and a1 to find the best fit line, to calculate this we use cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a Cost function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cost function is used to estimate the values of the coefficient for the best fit line.\n",
    "- Cost function optimizes the regression coefficients or weights. It measures how a linear regression model is performing.\n",
    "- For Linear Regression, we use the Mean Squared Error (MSE) as cost function, which is the average of squared error occurred between the predicted values and actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='mse2.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where,\n",
    "\n",
    "    N=Total number of observation\n",
    "    Yi = Actual value\n",
    "    (a1xi+a0)= Predicted value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuals: \n",
    "\n",
    "    The distance between the actual value and predicted values is called residual..\n",
    "    if residual high then cost function is high, if low then low.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- as the name suggest, its an optimization techniques, \n",
    "- used to minimize the MSE by calculating the gradient of the cost function.\n",
    "- A regression model uses gradient descent to update the coefficients\n",
    "- It is done by a random selection of values of coefficient and then iteratively update the values to reach the minimum cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is a Linear relationship between the features and target\n",
    "- Small or no multicollinearity between the features\n",
    "\n",
    "Homoscedasticity Assumption:\n",
    "\n",
    "Homoscedasticity is a situation when the error term is the same for all the values of input variables. With homoscedasticity, there should be no clear pattern distribution of data in the scatter plot.\n",
    "\n",
    "Normal distribution of error terms:\n",
    "\n",
    "Linear regression assumes that the error term should follow the normal distribution pattern. If error terms are not normally distributed, then confidence intervals will become either too wide or too narrow, which may cause difficulties in finding coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance of Regression Model:\n",
    "There are various metric for measuring performaces of a regression model, some r discussed below:\n",
    "- Mean Absolute Error (MAE)\n",
    "- Mean Absolute Percentage Error (MAPE) \n",
    "- Root Mean Square Error (RMSE)\n",
    "- R-squared values\n",
    "- Adjusted R-squared values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Absolute Error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finds average of absolute value of differences between the actual values and the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_absolute_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='mae.jpg' height=150 width=150>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Absolute Percentage Error (MAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='mape.jpg' height=150 width=150>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_absolute_percentage_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Percentage Error (MAPE):\n",
    "- It is the average of the ratio of the absolute difference between actual & predicted values, and actual value.\n",
    "- Lower the MAPE, better fit is the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually we can define a funcion to calculate MAPE\n",
    "\n",
    "def mape(y_test,y_pred):\n",
    "    error=np.mean(np.abs((y_test-y_pred)/y_test))*100\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Mean Square Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rmse_error=rmse(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMSE = SQRT(MSE)\n",
    "- Mean Absolute Error (MAE) is the sum of the absolute difference between actual and predicted values.\n",
    "- finds Square root of average of the sum of the square of difference between the actual and the predicted values.\n",
    "- lies between 0 and inf\n",
    "- lower value indicates a good model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEAN SQUARED ERROR:\n",
    "- As forecasted values can be less than or more than actual values, a simple sum of difference can be zero. This can lead to a false interpretation that forecast is accurate\n",
    "- As we take a square, all errors are positive, and mean is positive indicating there is some difference in estimates and actual. Lower mean indicates forecast is closer to actual\n",
    "- So MSE is influenced by large deviators or outliers, because sqaure of a single value can lead to higher mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R-Square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module is used \n",
    "> r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- also called a coefficient of determination, or coefficient of multiple determination for multiple regression.\n",
    "- indicates the percentage of the variation in the output variable explained by the input variable in the model\n",
    "- or measures the strength of the relationship between the dependent and independent variables on a scale of 0-100%.\n",
    "- lies between 0 and 1\n",
    "- a value closer to 1 indicates a good model, or Higher the R-square value better the model. \n",
    "- The value of R2 increases if we add more variables to the model irrespective of the variable contributing to the model or not. This is the disadvantage of using R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# r2_score(ypred-ytrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='r.jpg' height=150 width=150>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "579847579029"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusted R2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The disadvantage of R2 is fixed by the Adjusted R2 value. \n",
    "* it will improve only if the added variable is making a significant contribution to the model. \n",
    "* it adds penalty in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 or R Squared is a coefficient of determination. It is the total variance explained by model/total variance.\n",
    "\n",
    "1. Value of mse,rmse, mae lies between 0 to inf, whereas value of r2_sqaured lies between 0 and 1\n",
    "\n",
    "2. MSE/RMSE r sensitive to outliers,  But MAE and r2 are not sensitive..\n",
    "\n",
    "3. small value of mse/rmse and mae indicate better model whereas value near to 1 of r2 indicates a better model...\n",
    "\n",
    "RSME is always greater than or equal to MAE (RSME >= MAE). The greater difference between them indicates greater variance in individual errors in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Linear Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
