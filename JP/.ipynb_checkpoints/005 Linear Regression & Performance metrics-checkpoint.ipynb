{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A Supervised ml algortim\n",
    "- Models a linear relationship between a dependent (y) and one or more independent (y) variables,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='lr.jpg' width=250, hight=250>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                    img source: Javatpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically\n",
    "\n",
    "   y= mX+ b + ε\n",
    "   \n",
    "   c= intercept of the line \n",
    "   \n",
    "   m = regression coefficient/ slope\n",
    "   \n",
    "   ε = random error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Types of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Linear Regression: \n",
    "* it has only one input variable for prediction\n",
    "\n",
    "Multiple Linear regression: \n",
    "* more than one input variable used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Regression line??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It best fit line line showing the relationship between the input and output variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A regression line can show two types of relationship:\n",
    "\n",
    "1.Positive Linear Relationship: output increase with input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='lr1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Negative Linear Relationship: output decreases with increasing input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='lr3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best fit line:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Regression always try to find the best fit line that means the error between predicted values and actual values should be minimized.\n",
    "* The best fit line will have the least error.\n",
    "* The different values for weights or coefficient of lines (a0, a1) gives a different line of regression, so we need to calculate the best values for a0 and a1 to find the best fit line, to calculate this we use cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a Cost function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cost function is used to estimate the values of the coefficient for the best fit line.\n",
    "- Cost function optimizes the regression coefficients or weights. It measures how a linear regression model is performing.\n",
    "- For Linear Regression, we use the Mean Squared Error (MSE) as cost function, which is the average of squared error occurred between the predicted values and actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='mse2.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where,\n",
    "\n",
    "    N=Total number of observation\n",
    "    Yi = Actual value\n",
    "    (a1xi+a0)= Predicted value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residuals: \n",
    "\n",
    "    The distance between the actual value and predicted values is called residual..\n",
    "    if residual high then cost function is high, if low then low.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- as the name suggest, its an optimization techniques, \n",
    "- used to minimize the MSE by calculating the gradient of the cost function.\n",
    "- A regression model uses gradient descent to update the coefficients\n",
    "- It is done by a random selection of values of coefficient and then iteratively update the values to reach the minimum cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is a Linear relationship between the features and target\n",
    "- Small or no multicollinearity between the features\n",
    "\n",
    "Homoscedasticity Assumption:\n",
    "\n",
    "Homoscedasticity is a situation when the error term is the same for all the values of input variables. With homoscedasticity, there should be no clear pattern distribution of data in the scatter plot.\n",
    "\n",
    "Normal distribution of error terms:\n",
    "\n",
    "Linear regression assumes that the error term should follow the normal distribution pattern. If error terms are not normally distributed, then confidence intervals will become either too wide or too narrow, which may cause difficulties in finding coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance of Regression Model:\n",
    "There are various metric for measuring performaces of a regression model, some r discussed below:\n",
    "- Mean Absolute Error (MAE)\n",
    "- Mean Absolute Percentage Error (MAPE) \n",
    "- Root Mean Square Error (RMSE)\n",
    "- R-squared values\n",
    "- Adjusted R-squared values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Absolute Error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finds average of absolute value of differences between the actual values and the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_absolute_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='mae.jpg' height=150 width=150>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Absolute Percentage Error (MAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='mape.jpg' height=150 width=150>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean_absolute_percentage_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Percentage Error (MAPE):\n",
    "- It is the average of the ratio of the absolute difference between actual & predicted values, and actual value.\n",
    "- Lower the MAPE, better fit is the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually we can define a funcion to calculate MAPE\n",
    "\n",
    "def mape(y_test,y_pred):\n",
    "    error=np.mean(np.abs((y_test-y_pred)/y_test))*100\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Mean Square Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rmse_error=rmse(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMSE = SQRT(MSE)\n",
    "- Mean Absolute Error (MAE) is the sum of the absolute difference between actual and predicted values.\n",
    "- finds Square root of average of the sum of the square of difference between the actual and the predicted values.\n",
    "- lies between 0 and inf\n",
    "- lower value indicates a good model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEAN SQUARED ERROR:\n",
    "- As forecasted values can be less than or more than actual values, a simple sum of difference can be zero. This can lead to a false interpretation that forecast is accurate\n",
    "- As we take a square, all errors are positive, and mean is positive indicating there is some difference in estimates and actual. Lower mean indicates forecast is closer to actual\n",
    "- So MSE is influenced by large deviators or outliers, because sqaure of a single value can lead to higher mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R-Square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module is used \n",
    "> r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- also called a coefficient of determination, or coefficient of multiple determination for multiple regression.\n",
    "- indicates the percentage of the variation in the output variable explained by the input variable in the model\n",
    "- or measures the strength of the relationship between the dependent and independent variables on a scale of 0-100%.\n",
    "- lies between 0 and 1\n",
    "- a value closer to 1 indicates a good model, or Higher the R-square value better the model. \n",
    "- The value of R2 increases if we add more variables to the model irrespective of the variable contributing to the model or not. This is the disadvantage of using R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# r2_score(ypred-ytrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='r.jpg' height=150 width=150>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "579847579029"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusted R2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The disadvantage of R2 is fixed by the Adjusted R2 value. \n",
    "* it will improve only if the added variable is making a significant contribution to the model. \n",
    "* it adds penalty in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between R-squared and Adjusted R-squared for Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Residual Sum of Squares??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual for a point in the data is the difference between the actual value and the value predicted by our linear regression model.\n",
    "* residual= Actual Value- Predicted Value\n",
    "* Using the residual, we can determine the Residual sum of squares or RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='rss.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lower the value of RSS, the better is the model predictions.\n",
    "- based on above, a regression line can be considered to be a best fit line if it minimizes the RSS value\n",
    "- THE PROBLEM IS THAT RSS IS A SCALE VARIANT METRIC i.e. its value depends on the scale of the target variable.\n",
    "\n",
    "  THIS IS WHERE R-SQUARED COMES INTO PICTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Sum of Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total variation in target variable is the sum of squares of the difference between the actual values and their mean.\n",
    "<img src='tss.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RSS as a whole gives us the variation in the target variable that is not explained by our model... why???\n",
    "- R-squared = (TSS-RSS)/TSS\n",
    " \n",
    "  Explained variation/ Total variation\n",
    "  = 1 – Unexplained variation/ Total variation\n",
    "  \n",
    "So R-squared gives the degree of variability in the target variable that is explained by the model or the independent variables. If this value is 0.7, then it means that the independent variables explain 70% of the variation in the target variable.\n",
    "\n",
    "R-squared value always lies between 0 and 1. A higher R-squared value indicates a higher amount of variability being explained by our model and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the Problems with R-squared statistic??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared statistic isn’t perfect. \n",
    "\n",
    "In fact, it suffers from a major flaw. Its value never decreases no matter the number of variables we add to our regression model. \n",
    "\n",
    "That is, even if we are adding redundant variables to the data, the value of R-squared does not decrease. It either remains the same or increases with the addition of new independent variables.\n",
    "\n",
    "Because of this, because some of the independent variables might not be useful in determining the target variable. Adjusted R-squared deals with this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted R-squared statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- it takes into account the number of independent variables used for predicting the target variable\n",
    "\n",
    "<img src='adjusted-r2.jpg'>\n",
    "- n represents the number of data points in our dataset\n",
    "- k represents the number of independent variables, and\n",
    "- R represents the R-squared values determined by the model.\n",
    "\n",
    "So, if R-squared does not increase significantly on the addition of a new independent variable, then the value of Adjusted R-squared will actually decrease... see below\n",
    "\n",
    "<img src='adjusted-r2a.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 or R Squared is a coefficient of determination. It is the total variance explained by model/total variance.\n",
    "\n",
    "1. Value of mse,rmse, mae lies between 0 to inf, whereas value of r2_sqaured lies between 0 and 1\n",
    "\n",
    "2. MSE/RMSE r sensitive to outliers,  But MAE and r2 are not sensitive..\n",
    "\n",
    "3. small value of mse/rmse and mae indicate better model whereas value near to 1 of r2 indicates a better model...\n",
    "\n",
    "RSME is always greater than or equal to MAE (RSME >= MAE). The greater difference between them indicates greater variance in individual errors in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Linear Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
