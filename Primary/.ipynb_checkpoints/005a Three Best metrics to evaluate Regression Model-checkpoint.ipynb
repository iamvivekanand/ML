{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7319864",
   "metadata": {},
   "source": [
    "### 3 Best metrics to evaluate Regression Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba475e9",
   "metadata": {},
   "source": [
    "There are 3 main metrics for model evaluation in regression:\n",
    "\n",
    "1. R Square/Adjusted R Square\n",
    "2. Mean Square Error(MSE)/Root Mean Square Error(RMSE)\n",
    "3. Mean Absolute Error(MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8cf67d",
   "metadata": {},
   "source": [
    "#### r-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83412889",
   "metadata": {},
   "source": [
    "r2 measures how much variability in output can be explained by the model. It is the square of the Correlation Coefficient(R) and that is why it is called R-Squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e57b9d7",
   "metadata": {},
   "source": [
    "<img src='r2.JPG' width=300 height=50>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d8a41",
   "metadata": {},
   "source": [
    "- R Square value is between 0 to 1 \n",
    "- The ideal value for r-square is 1\n",
    "- A bigger value indicates a better fit between prediction and actual value.\n",
    "- However, it does not take into consideration of overfitting problem, because it fails to generalize with so many independent variables\n",
    "- Thats why we need adjusted R-sqaure in that case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef45dd",
   "metadata": {},
   "source": [
    "R-square is a comparison of the residual sum of squares (SSres) with the total sum of squares(SStot).\n",
    "\n",
    "The total sum of squares is calculated by summation of squares of perpendicular distance between data points and the average line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b67076",
   "metadata": {},
   "source": [
    "<img src='r2 graph.JPG' width=300 height=300 >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95b940b",
   "metadata": {},
   "source": [
    "- similarly residual sum of square can we calculated by somming of perpendicular distance between the data point and best fitted line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a4580",
   "metadata": {},
   "source": [
    "Note: The value of R-square can also be negative when the model fitted is worse than the average fitted model. \n",
    "\n",
    "Limitation of using the R-square method –\n",
    "\n",
    "- r2 always increases or remains the same when new variables are added to the model, irrespective of significance of feature added \n",
    "- meaning value of r2 never decreases on the addition of new attributes to the model. As a result, non-significant attributes can also be added to the model with an increase in the r-square value.  it can lead to overfitting of the model if there are large no. of variables.\n",
    "\n",
    "\n",
    "This is because SStot is always constant and the regression model tries to decrease the value of SSres by finding some correlation with this new attribute hence the overall value of r-square increases, which can lead to a poor regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf2bc2a",
   "metadata": {},
   "source": [
    "#### Adjusted R-Sqaured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70fb1a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# There is no directed formula for adjusted r2 in sklearn library, can use stats model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6361a9ea",
   "metadata": {},
   "source": [
    "<img src='adjr2.jpg' width=300 height=300 >\n",
    "\n",
    "                                            img source: geeksforgeeks.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e99bc2",
   "metadata": {},
   "source": [
    "Adjusted r-square is a modified form of r-square whose value increases if new predictors tend to improve model’s performance and decreases if new predictors do not improve performance as expected.\n",
    "- Adjusted r-square takes care of overfitting in this way\n",
    "\n",
    "Lets remind:\n",
    "        \n",
    "        SStotal = sum(Yi-Yavg)**2\n",
    "        SSres = sum(Yi-Ypred)**2\n",
    "        \n",
    "        r2=1 - (SSres / SStotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feaa5e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how the value of r2 always increases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716bb62d",
   "metadata": {},
   "source": [
    "SStot is always fixed for some data points if new predictors are added to the model, since what is the difference between Actual data and average of the data. but value of SSres decreases as model tries to find some correlations from the added predictors. Hence, r-square’s value always increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa30aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why Adjusted-R Square Test: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9350b62a",
   "metadata": {},
   "source": [
    "- to take care of complexity of the model\n",
    "- to count overfitting of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59d2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Square Error(MSE)/Root Mean Square Error(RMSE)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c6ae8ea",
   "metadata": {},
   "source": [
    "MSE is an absolute measure of the goodness for the fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c3a5d9",
   "metadata": {},
   "source": [
    "<img src='mse.jpg' width=200 height=150>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408ab931",
   "metadata": {},
   "source": [
    "- Root Mean Square Error(RMSE) is the square root of MSE. \n",
    "- It is used more commonly than MSE because firstly sometimes MSE value can be too big to compare easily. Secondly, MSE is calculated by the square of error, and thus square root brings it back to the same level of prediction error and makes it easier for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be93320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "# print(mean_squared_error(y_test, y_pred))\n",
    "# print(math.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "# MSE: 2017904593.23\n",
    "# RMSE: 44921.092965684235"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37baf18",
   "metadata": {},
   "source": [
    "### Mean Absolute Error(MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c0a86",
   "metadata": {},
   "source": [
    "- Mean Absolute Error(MAE) is similar to Mean Square Error(MSE). \n",
    "- However, instead of the sum of square of error in MSE, MAE is taking the sum of the absolute value of errors between Actual Value and Predicted Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf3d24a",
   "metadata": {},
   "source": [
    "<img src='mae.jpg' width=200 height=150>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b6b4a",
   "metadata": {},
   "source": [
    "Compare to MSE or RMSE, MAE is a more direct representation of sum of error terms. MSE gives larger penalization to big prediction error by square it while MAE treats all errors the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5f1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "# print(mean_absolute_error(y_test, y_pred))\n",
    "#MAE: 26745.1109986"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac4e357",
   "metadata": {},
   "source": [
    "Overall Recommendation/Conclusion\n",
    "\n",
    "R Square/Adjusted R Square is better used to explain the model to other people because you can explain the number as a percentage of the output variability. \n",
    "\n",
    "MSE, RMSE, or MAE are better be used to compare performance between different regression models. \n",
    "\n",
    "Personally, I would prefer using RMSE and I think Kaggle also uses it to assess the submission.\n",
    "\n",
    "However, it makes total sense to use MSE if the value is not too big and MAE if you do not want to penalize large prediction errors.\n",
    "\n",
    "Adjusted R square is the only metric here that considers the overfitting problem. \n",
    "\n",
    "R Square has a direct library in Python to calculate but I did not find a direct library to calculate Adjusted R square except using the statsmodel results. \n",
    "\n",
    "If you really want to calculate Adjusted R Square, you can use statsmodel or use its mathematic formula directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece312e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to calculate r2 and adjusted r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2018de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb04aa19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
