{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:44:51.533362Z",
     "iopub.status.busy": "2022-05-30T02:44:51.532633Z",
     "iopub.status.idle": "2022-05-30T02:44:51.563832Z",
     "shell.execute_reply": "2022-05-30T02:44:51.562924Z",
     "shell.execute_reply.started": "2022-05-30T02:44:51.533237Z"
    }
   },
   "source": [
    "import os\n",
    "for dirname, _,filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:45:20.989661Z",
     "iopub.status.busy": "2022-05-30T02:45:20.988944Z",
     "iopub.status.idle": "2022-05-30T02:45:22.022021Z",
     "shell.execute_reply": "2022-05-30T02:45:22.020923Z",
     "shell.execute_reply.started": "2022-05-30T02:45:20.989615Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Guys,Welcome to my notebook. Here I will try to explain each and every functions,module, statements used in this notebook. Even if u have not a simple peice of information about NLP or Text Analysis, you will understand this notebook so easily... keep reading..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:45:29.728655Z",
     "iopub.status.busy": "2022-05-30T02:45:29.728385Z",
     "iopub.status.idle": "2022-05-30T02:45:29.803618Z",
     "shell.execute_reply": "2022-05-30T02:45:29.802625Z",
     "shell.execute_reply.started": "2022-05-30T02:45:29.728629Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading train and test dataset\n",
    "train=pd.read_csv('disaster-tweets-train.csv')\n",
    "test=pd.read_csv('disaster-tweets-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:45:32.927911Z",
     "iopub.status.busy": "2022-05-30T02:45:32.927626Z",
     "iopub.status.idle": "2022-05-30T02:45:32.950236Z",
     "shell.execute_reply": "2022-05-30T02:45:32.949547Z",
     "shell.execute_reply.started": "2022-05-30T02:45:32.927884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:45:35.798680Z",
     "iopub.status.busy": "2022-05-30T02:45:35.798395Z",
     "iopub.status.idle": "2022-05-30T02:45:35.805558Z",
     "shell.execute_reply": "2022-05-30T02:45:35.804524Z",
     "shell.execute_reply.started": "2022-05-30T02:45:35.798652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WE HAVE 7613 ROWS AND 5 COLUMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:52:28.433908Z",
     "iopub.status.busy": "2022-05-30T02:52:28.433616Z",
     "iopub.status.idle": "2022-05-30T02:52:28.455511Z",
     "shell.execute_reply": "2022-05-30T02:52:28.454614Z",
     "shell.execute_reply.started": "2022-05-30T02:52:28.433880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, keyword, location, text, target]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# getting duplicates rows in id column\n",
    "duplicate_id=train[train.duplicated(keep='last')]\n",
    "print(duplicate_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> AS WE CAN SEE THERE IS NO DUPLICATED ID IN ID COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:53:28.349645Z",
     "iopub.status.busy": "2022-05-30T02:53:28.348903Z",
     "iopub.status.idle": "2022-05-30T02:53:28.360561Z",
     "shell.execute_reply": "2022-05-30T02:53:28.359586Z",
     "shell.execute_reply.started": "2022-05-30T02:53:28.349605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting null values in train dataset\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:54:21.688063Z",
     "iopub.status.busy": "2022-05-30T02:54:21.687301Z",
     "iopub.status.idle": "2022-05-30T02:54:21.693841Z",
     "shell.execute_reply": "2022-05-30T02:54:21.692852Z",
     "shell.execute_reply.started": "2022-05-30T02:54:21.688029Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping two columsn since they are not of much use\n",
    "train.drop(['location','keyword'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:54:23.388170Z",
     "iopub.status.busy": "2022-05-30T02:54:23.387839Z",
     "iopub.status.idle": "2022-05-30T02:54:23.398452Z",
     "shell.execute_reply": "2022-05-30T02:54:23.397521Z",
     "shell.execute_reply.started": "2022-05-30T02:54:23.388133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1   4             Forest fire near La Ronge Sask. Canada       1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:54:27.117811Z",
     "iopub.status.busy": "2022-05-30T02:54:27.117529Z",
     "iopub.status.idle": "2022-05-30T02:54:27.128367Z",
     "shell.execute_reply": "2022-05-30T02:54:27.127229Z",
     "shell.execute_reply.started": "2022-05-30T02:54:27.117777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "text      0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:45:17.862262Z",
     "iopub.status.busy": "2022-03-13T16:45:17.861621Z",
     "iopub.status.idle": "2022-03-13T16:45:17.868342Z",
     "shell.execute_reply": "2022-03-13T16:45:17.867796Z",
     "shell.execute_reply.started": "2022-03-13T16:45:17.862212Z"
    }
   },
   "source": [
    "**There is no null value left after dropping those unnecessary columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:56:42.289272Z",
     "iopub.status.busy": "2022-05-30T02:56:42.288948Z",
     "iopub.status.idle": "2022-05-30T02:56:42.298175Z",
     "shell.execute_reply": "2022-05-30T02:56:42.296763Z",
     "shell.execute_reply.started": "2022-05-30T02:56:42.289239Z"
    }
   },
   "outputs": [],
   "source": [
    "# making separate dataset of where tweets are disastrous (train.target==1), and non disastrous\n",
    "train_1=train[train['target']==1]\n",
    "train_0=train[train['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:57:13.688488Z",
     "iopub.status.busy": "2022-05-30T02:57:13.688217Z",
     "iopub.status.idle": "2022-05-30T02:57:13.695082Z",
     "shell.execute_reply": "2022-05-30T02:57:13.694429Z",
     "shell.execute_reply.started": "2022-05-30T02:57:13.688461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.96597924602653"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of disastrous tweets\n",
    "per=(len(train_1)/len(train))*100\n",
    "per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Around 43 percent of the total tweets are disastrous**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:58:06.509253Z",
     "iopub.status.busy": "2022-05-30T02:58:06.508667Z",
     "iopub.status.idle": "2022-05-30T02:58:06.514884Z",
     "shell.execute_reply": "2022-05-30T02:58:06.514191Z",
     "shell.execute_reply.started": "2022-05-30T02:58:06.509216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.03402075397347"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of non-disastrous (or fake disastrous) tweets\n",
    "per=(len(train_0)/len(train))*100\n",
    "per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Around 57 percent of the total tweets are non-disastrous**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:58:56.088210Z",
     "iopub.status.busy": "2022-05-30T02:58:56.087894Z",
     "iopub.status.idle": "2022-05-30T02:58:56.092030Z",
     "shell.execute_reply": "2022-05-30T02:58:56.091349Z",
     "shell.execute_reply.started": "2022-05-30T02:58:56.088175Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T02:59:09.809814Z",
     "iopub.status.busy": "2022-05-30T02:59:09.808936Z",
     "iopub.status.idle": "2022-05-30T02:59:10.038598Z",
     "shell.execute_reply": "2022-05-30T02:59:10.037451Z",
     "shell.execute_reply.started": "2022-05-30T02:59:09.809772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualising fake and real disastrous tweets\n",
    "sns.countplot(train['target'],palette='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of fake disastrous tweets are a little more than that of real disastrous tweets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"string\" module of python contains \"constants\" and \"classes\" for working with text.\n",
    "The \"constants\" is used to specify categories of characters such as ascii_letters and digits.\n",
    "\n",
    "Below, we have used such a constants named \"punctuation\" from \"string\" module of python, it returns all sets of punctuation.\n",
    "It Doesn’t take any parameter, since it’s not a function.\n",
    "See Below code and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T02:58:35.592485Z",
     "iopub.status.busy": "2022-03-14T02:58:35.592158Z",
     "iopub.status.idle": "2022-03-14T02:58:35.598424Z",
     "shell.execute_reply": "2022-03-14T02:58:35.597774Z",
     "shell.execute_reply.started": "2022-03-14T02:58:35.592455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "# print all punctuation\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T02:59:11.25512Z",
     "iopub.status.busy": "2022-03-14T02:59:11.254186Z",
     "iopub.status.idle": "2022-03-14T02:59:11.258372Z",
     "shell.execute_reply": "2022-03-14T02:59:11.257641Z",
     "shell.execute_reply.started": "2022-03-14T02:59:11.255071Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# see terms's explanation below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Language Toolkit (NLTK) is a widely used, open-source Python library for NLP (NLTK Project, 2018). Several algorithms are available for working with test data e.g. text tokenization, stemming, stop word removal, classification, clustering, PoS tagging, parsing, and semantic reasoning. It also provides wrappers for other NLP libraries.\n",
    "\n",
    "A corpus can be defined as a collection of text documents. It can be thought as just a bunch of text files in a directory, often alongside many other directories of text files.\n",
    "\n",
    "Stopwords are the English words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. For example, the words like the, he, have etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:00:41.811841Z",
     "iopub.status.busy": "2022-03-14T03:00:41.811566Z",
     "iopub.status.idle": "2022-03-14T03:00:41.823148Z",
     "shell.execute_reply": "2022-03-14T03:00:41.821781Z",
     "shell.execute_reply.started": "2022-03-14T03:00:41.811814Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
     ]
    }
   ],
   "source": [
    "# printing list of all stopwords in english\n",
    "print(stopwords.words('english'),end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> U can see that most of the stopwords are pronouns, auxiliary verbs, helping verbs, prepositions, conjuctions etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing all stop words in a variable for future use\n",
    "stopwords_=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:01:45.195756Z",
     "iopub.status.busy": "2022-03-14T03:01:45.195462Z",
     "iopub.status.idle": "2022-03-14T03:01:45.201138Z",
     "shell.execute_reply": "2022-03-14T03:01:45.200379Z",
     "shell.execute_reply.started": "2022-03-14T03:01:45.195732Z"
    }
   },
   "source": [
    "def text_cleaning(text):\n",
    "# taking only characters  without any punctuation\n",
    "    text_punc_removed = [x for x in text if x not in string.punctuation]\n",
    "    text_punc_removed_joined = ''.join(text_punc_removed)\n",
    "    text_punc_removed_joined_splitted = [x   for x in text_punc_removed_joined.split(' ') if x not in stopwords_]\n",
    "    return text_punc_removed_joined_splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning\n",
    "text = [x for x in train['text'] if x not in string.punctuation]\n",
    "text = ''.join(text)\n",
    "text = [x for x in text.split(' ') if x not in stopwords_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In order to use textual data for predictive modeling, the text must be parsed(resolved into compenent parts) to remove certain words – this process is called tokenization.** \n",
    "\n",
    "> These words need to then be encoded as integers, or floating-point values, for use as inputs in machine learning algorithms. This process is called feature extraction (or vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:03:23.904311Z",
     "iopub.status.busy": "2022-03-14T03:03:23.903938Z",
     "iopub.status.idle": "2022-03-14T03:03:23.907398Z",
     "shell.execute_reply": "2022-03-14T03:03:23.906499Z",
     "shell.execute_reply.started": "2022-03-14T03:03:23.904274Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# CountVectorizer is used to convert a collection of text documents to a vector of term/token counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The sklearn.feature_extraction module can be used to extract features in a format supported by machine learning algorithms from datasets consisting of formats such as text and image.\n",
    "\n",
    "> Feature extraction is very different from Feature selection: \"Feature extraction\" helps in transforming arbitrary data, such as text or images, into numerical features usable for machine learning. While \"feature_selection\" is a machine learning technique applied on these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=cv.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Our Deeds are the Reason of this #earthquake M...\n",
       "1                  Forest fire near La Ronge Sask. Canada\n",
       "2       All residents asked to 'shelter in place' are ...\n",
       "3       13,000 people receive #wildfires evacuation or...\n",
       "4       Just got sent this photo from Ruby #Alaska as ...\n",
       "                              ...                        \n",
       "7608    Two giant cranes holding a bridge collapse int...\n",
       "7609    @aria_ahrary @TheTawniest The out of control w...\n",
       "7610    M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...\n",
       "7611    Police investigating after an e-bike collided ...\n",
       "7612    The Latest: More Homes Razed by Northern Calif...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****There are 7613 disasterous tweets and 26918 unique words.****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:06:41.752356Z",
     "iopub.status.busy": "2022-03-14T03:06:41.752112Z",
     "iopub.status.idle": "2022-03-14T03:06:41.755656Z",
     "shell.execute_reply": "2022-03-14T03:06:41.754895Z",
     "shell.execute_reply.started": "2022-03-14T03:06:41.75233Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:06:48.39504Z",
     "iopub.status.busy": "2022-03-14T03:06:48.394603Z",
     "iopub.status.idle": "2022-03-14T03:06:48.397889Z",
     "shell.execute_reply": "2022-03-14T03:06:48.39742Z",
     "shell.execute_reply.started": "2022-03-14T03:06:48.395014Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:06:53.760916Z",
     "iopub.status.busy": "2022-03-14T03:06:53.760621Z",
     "iopub.status.idle": "2022-03-14T03:06:54.112645Z",
     "shell.execute_reply": "2022-03-14T03:06:54.111659Z",
     "shell.execute_reply.started": "2022-03-14T03:06:53.760887Z"
    }
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:07:00.279082Z",
     "iopub.status.busy": "2022-03-14T03:07:00.278815Z",
     "iopub.status.idle": "2022-03-14T03:07:05.940225Z",
     "shell.execute_reply": "2022-03-14T03:07:05.939643Z",
     "shell.execute_reply.started": "2022-03-14T03:07:00.27905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:07:12.318299Z",
     "iopub.status.busy": "2022-03-14T03:07:12.318043Z",
     "iopub.status.idle": "2022-03-14T03:07:12.42229Z",
     "shell.execute_reply": "2022-03-14T03:07:12.421506Z",
     "shell.execute_reply.started": "2022-03-14T03:07:12.318275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7951680672268907"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "lr_pred=lr.predict(xtest)\n",
    "accuracy_score(ytest,lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:07:28.771409Z",
     "iopub.status.busy": "2022-03-14T03:07:28.77118Z",
     "iopub.status.idle": "2022-03-14T03:10:20.953862Z",
     "shell.execute_reply": "2022-03-14T03:10:20.953082Z",
     "shell.execute_reply.started": "2022-03-14T03:07:28.771387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7394957983193278"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier()\n",
    "dtc.fit(xtrain,ytrain)\n",
    "dtc_pred=dtc.predict(xtest)\n",
    "accuracy_score(ytest,dtc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:10:20.95554Z",
     "iopub.status.busy": "2022-03-14T03:10:20.955341Z",
     "iopub.status.idle": "2022-03-14T03:12:10.411254Z",
     "shell.execute_reply": "2022-03-14T03:12:10.410436Z",
     "shell.execute_reply.started": "2022-03-14T03:10:20.955515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7888655462184874"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(xtrain,ytrain)\n",
    "rfc_pred=rfc.predict(xtest)\n",
    "accuracy_score(ytest,rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:12:10.412619Z",
     "iopub.status.busy": "2022-03-14T03:12:10.412443Z",
     "iopub.status.idle": "2022-03-14T03:12:10.416351Z",
     "shell.execute_reply": "2022-03-14T03:12:10.415512Z",
     "shell.execute_reply.started": "2022-03-14T03:12:10.412594Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Working with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:12:57.532144Z",
     "iopub.status.busy": "2022-03-14T03:12:57.531873Z",
     "iopub.status.idle": "2022-03-14T03:12:57.543395Z",
     "shell.execute_reply": "2022-03-14T03:12:57.542431Z",
     "shell.execute_reply.started": "2022-03-14T03:12:57.532113Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:13:04.308778Z",
     "iopub.status.busy": "2022-03-14T03:13:04.308503Z",
     "iopub.status.idle": "2022-03-14T03:13:04.313363Z",
     "shell.execute_reply": "2022-03-14T03:13:04.31277Z",
     "shell.execute_reply.started": "2022-03-14T03:13:04.308743Z"
    }
   },
   "outputs": [],
   "source": [
    "test.drop(['keyword','location'],axis=1,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:13:06.972984Z",
     "iopub.status.busy": "2022-03-14T03:13:06.972638Z",
     "iopub.status.idle": "2022-03-14T03:13:06.9806Z",
     "shell.execute_reply": "2022-03-14T03:13:06.980171Z",
     "shell.execute_reply.started": "2022-03-14T03:13:06.972959Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:13:15.947134Z",
     "iopub.status.busy": "2022-03-14T03:13:15.946813Z",
     "iopub.status.idle": "2022-03-14T03:13:21.050657Z",
     "shell.execute_reply": "2022-03-14T03:13:21.050195Z",
     "shell.execute_reply.started": "2022-03-14T03:13:15.947111Z"
    }
   },
   "outputs": [],
   "source": [
    "test_vectorizer=vectorizer.transform(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:13:26.643467Z",
     "iopub.status.busy": "2022-03-14T03:13:26.643135Z",
     "iopub.status.idle": "2022-03-14T03:13:26.648157Z",
     "shell.execute_reply": "2022-03-14T03:13:26.647075Z",
     "shell.execute_reply.started": "2022-03-14T03:13:26.643444Z"
    }
   },
   "outputs": [],
   "source": [
    "final_pred=lr.predict(test_vectorizer)\n",
    "# we are using logistic regression for the final prediction since it has the highest accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:13:30.250467Z",
     "iopub.status.busy": "2022-03-14T03:13:30.249536Z",
     "iopub.status.idle": "2022-03-14T03:13:30.2538Z",
     "shell.execute_reply": "2022-03-14T03:13:30.253348Z",
     "shell.execute_reply.started": "2022-03-14T03:13:30.25042Z"
    }
   },
   "outputs": [],
   "source": [
    "my_pred={'id':test['id'],'target':final_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:13:37.025684Z",
     "iopub.status.busy": "2022-03-14T03:13:37.024721Z",
     "iopub.status.idle": "2022-03-14T03:13:37.030055Z",
     "shell.execute_reply": "2022-03-14T03:13:37.029127Z",
     "shell.execute_reply.started": "2022-03-14T03:13:37.025644Z"
    }
   },
   "outputs": [],
   "source": [
    "my_submission=pd.DataFrame(my_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T03:13:39.900722Z",
     "iopub.status.busy": "2022-03-14T03:13:39.89975Z",
     "iopub.status.idle": "2022-03-14T03:13:39.909183Z",
     "shell.execute_reply": "2022-03-14T03:13:39.908455Z",
     "shell.execute_reply.started": "2022-03-14T03:13:39.900695Z"
    }
   },
   "outputs": [],
   "source": [
    "my_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('disaster-tweets-train.csv')\n",
    "test=pd.read_csv('disaster-tweets-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* WE HAVE DUPLIATE ROWS IN TEXT COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.id.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "There are 4271 duplicate values in the location column\n"
     ]
    }
   ],
   "source": [
    "print(train.location.duplicated().any())\n",
    "print('There are',train.location.duplicated().sum(),'duplicate values in the location column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* WE HAVE 110 DUPLICATE ROWS IN THE COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['keyword','location'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# removing duplicate rows\n",
    "train.text.drop_duplicates(keep='last',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22784/3596539398.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# train['text']=re.sub('http://.+','',train['text'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# train['text']=re.sub('https://.+','',train['text'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "train['text']=[i for i in train['text'] if i not in string.punctuation]\n",
    "train['text']=''.join(train['text'])\n",
    "# train['text']=re.sub('http://.+','',train['text'])\n",
    "# train['text']=re.sub('https://.+','',train['text'])\n",
    "train['text']=[i for i in train['text'].split(' ') if i not in sw]\n",
    "train['text'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we are done with preprocessing cleaning, we will start developing the model.\n",
    "* before we develop the model, it is necessory that our textual data get converted into a vector or numnerical form for use in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1   4             Forest fire near La Ronge Sask. Canada       1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7064, 7613]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13260/3640850077.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2170\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2172\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \"\"\"\n\u001b[0;32m    355\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [7064, 7613]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.20,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
